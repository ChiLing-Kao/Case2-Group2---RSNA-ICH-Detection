{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Package                  Version    \n",
      "------------------------ -----------\n",
      "alabaster                0.7.12     \n",
      "apex                     0.1        \n",
      "asn1crypto               0.24.0     \n",
      "atomicwrites             1.2.1      \n",
      "attrs                    18.2.0     \n",
      "Babel                    2.6.0      \n",
      "backcall                 0.1.0      \n",
      "beautifulsoup4           4.6.3      \n",
      "bleach                   3.0.2      \n",
      "certifi                  2018.10.15 \n",
      "cffi                     1.11.5     \n",
      "chardet                  3.0.4      \n",
      "Click                    7.0        \n",
      "codecov                  2.0.15     \n",
      "conda                    4.5.11     \n",
      "conda-build              3.16.3     \n",
      "coverage                 4.5.2      \n",
      "cryptography             2.4.1      \n",
      "cycler                   0.10.0     \n",
      "cymem                    2.0.2      \n",
      "cytoolz                  0.9.0.1    \n",
      "decorator                4.3.0      \n",
      "defusedxml               0.5.0      \n",
      "dill                     0.2.8.2    \n",
      "docutils                 0.14       \n",
      "entrypoints              0.2.3      \n",
      "filelock                 3.0.10     \n",
      "flake8                   3.6.0      \n",
      "Flask                    1.0.2      \n",
      "future                   0.17.1     \n",
      "glob2                    0.6        \n",
      "hypothesis               3.82.1     \n",
      "idna                     2.7        \n",
      "imagesize                1.1.0      \n",
      "ipykernel                5.1.0      \n",
      "ipython                  7.2.0      \n",
      "ipython-genutils         0.2.0      \n",
      "ipywidgets               7.4.2      \n",
      "itsdangerous             1.1.0      \n",
      "jedi                     0.13.1     \n",
      "Jinja2                   2.10       \n",
      "jsonschema               2.6.0      \n",
      "jupyter                  1.0.0      \n",
      "jupyter-client           5.2.3      \n",
      "jupyter-console          6.0.0      \n",
      "jupyter-core             4.4.0      \n",
      "kiwisolver               1.0.1      \n",
      "libarchive-c             2.8        \n",
      "lmdb                     0.94       \n",
      "MarkupSafe               1.1.0      \n",
      "matplotlib               3.0.2      \n",
      "mccabe                   0.6.1      \n",
      "mistune                  0.8.4      \n",
      "mock                     2.0.0      \n",
      "more-itertools           4.3.0      \n",
      "msgpack                  0.5.6      \n",
      "msgpack-numpy            0.4.3.2    \n",
      "murmurhash               1.0.1      \n",
      "nbconvert                5.4.0      \n",
      "nbformat                 4.4.0      \n",
      "networkx                 2.0        \n",
      "ninja                    1.8.2.post2\n",
      "nltk                     3.4        \n",
      "notebook                 5.7.2      \n",
      "numpy                    1.15.4     \n",
      "nvidia-dali              0.5.0      \n",
      "onnx                     1.3.0      \n",
      "packaging                18.0       \n",
      "pandocfilters            1.4.2      \n",
      "parso                    0.3.1      \n",
      "pbr                      5.1.1      \n",
      "pexpect                  4.6.0      \n",
      "pickleshare              0.7.5      \n",
      "Pillow-SIMD              5.3.0.post0\n",
      "pip                      19.1       \n",
      "pkginfo                  1.4.2      \n",
      "plac                     0.9.6      \n",
      "pluggy                   0.8.0      \n",
      "preshed                  2.0.1      \n",
      "prometheus-client        0.4.2      \n",
      "prompt-toolkit           2.0.7      \n",
      "protobuf                 3.6.1      \n",
      "psutil                   5.4.8      \n",
      "ptyprocess               0.6.0      \n",
      "py                       1.7.0      \n",
      "pycodestyle              2.4.0      \n",
      "pycosat                  0.6.3      \n",
      "pycparser                2.19       \n",
      "pydot                    1.3.0      \n",
      "pyflakes                 2.0.0      \n",
      "Pygments                 2.2.0      \n",
      "pyOpenSSL                18.0.0     \n",
      "pyparsing                2.3.0      \n",
      "PySocks                  1.6.8      \n",
      "pytest                   4.0.1      \n",
      "pytest-cov               2.6.0      \n",
      "pytest-pythonpath        0.7.3      \n",
      "python-dateutil          2.7.5      \n",
      "python-nvd3              0.15.0     \n",
      "python-slugify           1.2.6      \n",
      "pytz                     2018.7     \n",
      "PyYAML                   3.13       \n",
      "pyzmq                    17.1.2     \n",
      "qtconsole                4.4.3      \n",
      "regex                    2018.1.10  \n",
      "requests                 2.20.1     \n",
      "revtok                   0.0.3      \n",
      "ruamel-yaml              0.15.46    \n",
      "sacrebleu                1.2.10     \n",
      "sacremoses               0.0.5      \n",
      "scipy                    1.1.0      \n",
      "Send2Trash               1.5.0      \n",
      "setuptools               40.6.2     \n",
      "singledispatch           3.4.0.3    \n",
      "six                      1.11.0     \n",
      "snowballstemmer          1.2.1      \n",
      "spacy                    2.0.16     \n",
      "Sphinx                   1.8.2      \n",
      "sphinx-rtd-theme         0.4.2      \n",
      "sphinxcontrib-websupport 1.1.0      \n",
      "tabulate                 0.8.2      \n",
      "terminado                0.8.1      \n",
      "testpath                 0.4.2      \n",
      "thinc                    6.12.0     \n",
      "toolz                    0.9.0      \n",
      "torch                    1.0.0a0    \n",
      "torchtext                0.4.0      \n",
      "torchvision              0.2.1      \n",
      "tornado                  5.1.1      \n",
      "tqdm                     4.28.1     \n",
      "traitlets                4.3.2      \n",
      "typing                   3.6.6      \n",
      "typing-extensions        3.6.6      \n",
      "ujson                    1.35       \n",
      "Unidecode                1.0.23     \n",
      "urllib3                  1.23       \n",
      "wcwidth                  0.1.7      \n",
      "webencodings             0.5.1      \n",
      "Werkzeug                 0.14.1     \n",
      "wheel                    0.32.3     \n",
      "widgetsnbextension       3.4.2      \n",
      "wrapt                    1.10.11    \n",
      "\u001b[33mWARNING: You are using pip version 19.1, however version 20.2.4 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "img_width = 528\n",
    "img_height = 528\n",
    "\n",
    "train_path = \"./train_drop_ROI/\"\n",
    "train_path0 = os.listdir(train_path + \"epidural\")\n",
    "train_path1 = os.listdir(train_path + \"healthy\")\n",
    "train_path2 = os.listdir(train_path + \"intraparenchymal\")\n",
    "train_path3 = os.listdir(train_path + \"intraventricular\")\n",
    "train_path4 = os.listdir(train_path + \"subarachnoid\")\n",
    "train_path5 = os.listdir(train_path + \"subdural\")\n",
    "\n",
    "train_data0 = []\n",
    "for i in range(len(train_path0)):\n",
    "    train_image = cv2.imread(os.path.join(train_path + \"epidural/\", train_path0[i]))[:,:,::-1]\n",
    "    train_image = cv2.resize(train_image, (img_width, img_height))\n",
    "    train_data0.append(train_image)\n",
    "train_data0 = np.array(train_data0)\n",
    "    \n",
    "train_data1 = []\n",
    "for i in range(len(train_path1)):\n",
    "    train_image = cv2.imread(os.path.join(train_path + \"healthy/\", train_path1[i]))[:,:,::-1]\n",
    "    train_image = cv2.resize(train_image, (img_width, img_height))\n",
    "    train_data1.append(train_image)\n",
    "train_data1 = np.array(train_data1)\n",
    "\n",
    "train_data2 = []\n",
    "for i in range(len(train_path2)):\n",
    "    train_image = cv2.imread(os.path.join(train_path + \"intraparenchymal/\", train_path2[i]))[:,:,::-1]\n",
    "    train_image = cv2.resize(train_image, (img_width, img_height))\n",
    "    train_data2.append(train_image)\n",
    "train_data2 = np.array(train_data2)\n",
    "\n",
    "train_data3 = []\n",
    "for i in range(len(train_path3)):\n",
    "    train_image = cv2.imread(os.path.join(train_path + \"intraventricular/\", train_path3[i]))[:,:,::-1]\n",
    "    train_image = cv2.resize(train_image, (img_width, img_height))\n",
    "    train_data3.append(train_image)\n",
    "train_data3 = np.array(train_data3)\n",
    "\n",
    "train_data4 = []\n",
    "for i in range(len(train_path4)):\n",
    "    train_image = cv2.imread(os.path.join(train_path + \"subarachnoid/\", train_path4[i]))[:,:,::-1]\n",
    "    train_image = cv2.resize(train_image, (img_width, img_height))\n",
    "    train_data4.append(train_image)\n",
    "train_data4 = np.array(train_data4)\n",
    "\n",
    "train_data5 = []\n",
    "for i in range(len(train_path5)):\n",
    "    train_image = cv2.imread(os.path.join(train_path + \"subdural/\", train_path5[i]))[:,:,::-1]\n",
    "    train_image = cv2.resize(train_image, (img_width, img_height))\n",
    "    train_data5.append(train_image)\n",
    "train_data5 = np.array(train_data5)\n",
    "\n",
    "train_data = np.concatenate([train_data0,\n",
    "                             train_data1,\n",
    "                             train_data2,\n",
    "                             train_data3,\n",
    "                             train_data4,\n",
    "                             train_data5], 0)\n",
    "train_label = np.concatenate([[0]*(len(train_data0)),\n",
    "                              [1]*(len(train_data1)),\n",
    "                              [2]*(len(train_data2)),\n",
    "                              [3]*(len(train_data3)),\n",
    "                              [4]*(len(train_data4)),\n",
    "                              [5]*(len(train_data5))], 0)\n",
    "\n",
    "\n",
    "val_path = \"./val_drop_ROI/\"\n",
    "val_path0 = os.listdir(val_path + \"epidural\")\n",
    "val_path1 = os.listdir(val_path + \"healthy\")\n",
    "val_path2 = os.listdir(val_path + \"intraparenchymal\")\n",
    "val_path3 = os.listdir(val_path + \"intraventricular\")\n",
    "val_path4 = os.listdir(val_path + \"subarachnoid\")\n",
    "val_path5 = os.listdir(val_path + \"subdural\")\n",
    "\n",
    "val_data0 = []\n",
    "for i in range(len(val_path0)):\n",
    "    val_image = cv2.imread(os.path.join(val_path + \"epidural/\", val_path0[i]))[:,:,::-1]\n",
    "    val_image = cv2.resize(val_image, (img_width, img_height))\n",
    "    val_data0.append(val_image)\n",
    "val_data0 = np.array(val_data0)\n",
    "    \n",
    "val_data1 = []\n",
    "for i in range(len(val_path1)):\n",
    "    val_image = cv2.imread(os.path.join(val_path + \"healthy/\", val_path1[i]))[:,:,::-1]\n",
    "    val_image = cv2.resize(val_image, (img_width, img_height))\n",
    "    val_data1.append(val_image)\n",
    "val_data1 = np.array(val_data1)\n",
    "\n",
    "val_data2 = []\n",
    "for i in range(len(val_path2)):\n",
    "    val_image = cv2.imread(os.path.join(val_path + \"intraparenchymal/\", val_path2[i]))[:,:,::-1]\n",
    "    val_image = cv2.resize(val_image, (img_width, img_height))\n",
    "    val_data2.append(val_image)\n",
    "val_data2 = np.array(val_data2)\n",
    "\n",
    "val_data3 = []\n",
    "for i in range(len(val_path3)):\n",
    "    val_image = cv2.imread(os.path.join(val_path + \"intraventricular/\", val_path3[i]))[:,:,::-1]\n",
    "    val_image = cv2.resize(val_image, (img_width, img_height))\n",
    "    val_data3.append(val_image)\n",
    "val_data3 = np.array(val_data3)\n",
    "\n",
    "val_data4 = []\n",
    "for i in range(len(val_path4)):\n",
    "    val_image = cv2.imread(os.path.join(val_path + \"subarachnoid/\", val_path4[i]))[:,:,::-1]\n",
    "    val_image = cv2.resize(val_image, (img_width, img_height))\n",
    "    val_data4.append(val_image)\n",
    "val_data4 = np.array(val_data4)\n",
    "\n",
    "val_data5 = []\n",
    "for i in range(len(val_path5)):\n",
    "    val_image = cv2.imread(os.path.join(val_path + \"subdural/\", val_path5[i]))[:,:,::-1]\n",
    "    val_image = cv2.resize(val_image, (img_width, img_height))\n",
    "    val_data5.append(val_image)\n",
    "val_data5 = np.array(val_data5)\n",
    "\n",
    "val_data = np.concatenate([val_data0,\n",
    "                           val_data1,\n",
    "                           val_data2,\n",
    "                           val_data3,\n",
    "                           val_data4,\n",
    "                           val_data5], 0)\n",
    "val_label = np.concatenate([[0]*(len(val_data0)),\n",
    "                            [1]*(len(val_data1)),\n",
    "                            [2]*(len(val_data2)),\n",
    "                            [3]*(len(val_data3)),\n",
    "                            [4]*(len(val_data4)),\n",
    "                            [5]*(len(val_data5))], 0)\n",
    "\n",
    "# test_path = \"D:/shiang/course/MachineLearning/10802Wei/AIdea/data/aoi/test/\"\n",
    "# test_path_image = os.listdir(test_path + \"image\")\n",
    "\n",
    "# test_data = []\n",
    "# for i in range(len(test_path_image)):\n",
    "#     test_image = cv2.imread(os.path.join(test_path + \"image/\", test_path_image[i]))[:,:,::-1]\n",
    "#     test_image = cv2.resize(test_image, (img_width, img_height))\n",
    "#     test_data.append(test_image)\n",
    "# test_data = np.array(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] =\"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'absl'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-0ca82b29604d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclient\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdevice_lib\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice_lib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlist_local_devices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msys\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0m_sys\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtools\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmodule_util\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0m_module_util\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlazy_loader\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLazyLoader\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0m_LazyLoader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;31m# pylint: disable=wildcard-import,g-bad-import-order,g-import-not-at-top\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meager\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;31m# pylint: enable=wildcard-import\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/eager/context.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mthreading\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mabsl\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlogging\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'absl'"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'absl'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-8816c77ff564>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_gpu_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msys\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0m_sys\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtools\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmodule_util\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0m_module_util\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlazy_loader\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLazyLoader\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0m_LazyLoader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;31m# pylint: disable=wildcard-import,g-bad-import-order,g-import-not-at-top\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meager\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;31m# pylint: enable=wildcard-import\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/eager/context.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mthreading\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mabsl\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlogging\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'absl'"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "print(tf.test.is_gpu_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import tensorflow.keras.applications.efficientnet\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.utils import multi_gpu_model\n",
    "\n",
    "epochs = 25\n",
    "def step_decay(epoch):     \n",
    "    if (epoch < 5):\n",
    "        return(5e-5)\n",
    "    elif (epoch < 10):\n",
    "        return(7e-6)\n",
    "    elif (epoch < 15):\n",
    "        return(3e-6)\n",
    "    elif (epoch < 20):\n",
    "        return(8e-7)\n",
    "    else:\n",
    "        return(1e-7)\n",
    "\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler\n",
    "lrate = LearningRateScheduler(step_decay, verbose=1)\n",
    "callbacks_list = [lrate]\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "                            width_shift_range = 0.0,     # 水平平移\n",
    "                            height_shift_range = 0.0,    # 垂直平移\n",
    "                            rotation_range = 20,         # 0-180 任一角度旋轉\n",
    "                            horizontal_flip = True,      # 任意水平翻轉\n",
    "                            vertical_flip = True,        # 任意垂直翻轉\n",
    "                            fill_mode = \"constant\",      # 在旋轉或平移時，有空隙發生，則空隙補常數\n",
    "                            cval = 0                     # 設定常數值為 0\n",
    "                            )\n",
    "\n",
    "pre_model = tf.keras.applications.EfficientNetB6(include_top = False, weights='imagenet', pooling='avg')\n",
    "x = pre_model.output\n",
    "output_layer = Dense(6, activation ='softmax')(x)\n",
    "model = Model(inputs = pre_model.input, outputs = output_layer)\n",
    "\n",
    "for layer in model.layers[:-2]:\n",
    "    layer.trainable = True\n",
    "for layer in model.layers[-2:]:\n",
    "    layer.trainable = True \n",
    "\n",
    "for x in model.trainable_weights:\n",
    "    print(x.name)\n",
    "#    model.summary() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "    \n",
    "batch_size = 16\n",
    "# model = multi_gpu_model(model, gpus = 2, cpu_merge = False)\n",
    "model.compile(optimizer = Adam(), loss = 'categorical_crossentropy', metrics = ['accuracy'])   \n",
    "model_history = model.fit_generator(\n",
    "                                    datagen.flow(train_data, np.eye(6)[train_label], batch_size = batch_size),\n",
    "                                    steps_per_epoch = len(train_label) / batch_size,\n",
    "                                    validation_data = (val_data, np.eye(6)[val_label]),\n",
    "                                    epochs = epochs, \n",
    "                                    verbose = 1,\n",
    "                                    callbacks = callbacks_list\n",
    "                                    )   \n",
    "    \n",
    "train_acc_history = model_history.history['accuracy']\n",
    "train_loss_history = model_history.history['loss']\n",
    "val_acc_history = model_history.history['val_accuracy']\n",
    "val_loss_history = model_history.history['val_loss']\n",
    "\n",
    "# test_acc_history = model_history.history['val_acc']\n",
    "# test_loss_history = model_history.history['val_loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize = (13,4))\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(train_loss_history)\n",
    "plt.plot(val_loss_history)\n",
    "plt.legend(loc = \"lower left\")\n",
    "plt.legend(['Train','Validation'])\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(train_acc_history)\n",
    "plt.plot(val_acc_history)\n",
    "plt.legend(loc = \"lower right\")\n",
    "plt.legend(['Train','Validation'])\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "\n",
    "plt.savefig('./20201110_DM_loss.png', dpi = 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('20201110_DM.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score \n",
    "\n",
    "val_predict_prob = model.predict(val_data)\n",
    "val_predict_label = np.argmax(val_predict_prob, axis = 1)\n",
    "\n",
    "test_predict_prob = model.predict(test_data)\n",
    "test_predict_label = np.argmax(test_predict_prob, axis = 1)\n",
    "\n",
    "#pred = model.predict(test_data).round()\n",
    "\n",
    "cm = confusion_matrix(val_label, val_predict_label)\n",
    "# cm = confusion_matrix(test_label.argmax(-1), test_predict_label)\n",
    "# acc = accuracy_score(val_label, val_predict_label)\n",
    "\n",
    "import seaborn as sns\n",
    "class_names = [0,1,2,3,4,5]\n",
    "matrix = np.arange(36).reshape((6, 6))\n",
    "plt.figure(figsize = (7, 7))\n",
    "sns.set(font_scale = 1.5)\n",
    "sns.heatmap(cm, annot = True, cbar = True, cmap = \"Blues\",  fmt = '2.0f',\n",
    "            xticklabels = class_names,\n",
    "            yticklabels = class_names)\n",
    "plt.ylabel('True Label', fontsize = 15)\n",
    "plt.xlabel('Predicted Label', fontsize = 16)\n",
    "plt.title('ML_AOI_val \\nAccuracy:{0:.3f}'.format(accuracy_score(val_label, val_predict_label)), fontsize=20)\n",
    "plt.show()\n",
    "plt.savefig('./20200612b4v2_ML_AOI_val_cm.png', dpi = 300)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
